from flask import Flask, request, jsonify, render_template, session, Response
from flask_session import Session
import redis
from flask_cors import CORS
import oracledb
import os
import re
import uuid
import schedule
import time
from sqlalchemy import create_engine, MetaData, Column, Integer, String, ForeignKey, DateTime, Text
from sqlalchemy.orm import sessionmaker, declarative_base, relationship
import datetime
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from deep_translator import GoogleTranslator
from openai import OpenAI  
from dotenv import load_dotenv
import sys
import io
import threading
import numpy as np
import json
import traceback
from werkzeug.security import generate_password_hash, check_password_hash
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
import smtplib
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime
import subprocess
import secrets
from langdetect import detect, LangDetectException
import logging
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import OpenAI as LangOpenAI
import time

THRESHOLD_TIME = 2.0

load_dotenv()

app = Flask(__name__)
CORS(app, supports_credentials=True)  


# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ Ø³Ø±ÙŠ Ù„Ù„Ø¬Ù„Ø³Ø§Øª
app.secret_key = os.getenv("SECRET_KEY", secrets.token_hex(32))  # Ù…ÙØªØ§Ø­ Ø¢Ù…Ù†

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask-Session Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis
app.config["SESSION_TYPE"] = "redis"
app.config["SESSION_REDIS"] = redis.from_url("redis://localhost:6379") 
app.config["SESSION_PERMANENT"] = False
app.config["SESSION_USE_SIGNER"] = True

Session(app)

# ===== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§ØªØµØ§Ù„ Ø£ÙˆØ±Ø§ÙƒÙ„ =====
os.environ["NLS_LANG"] = "AMERICAN_AMERICA.AL32UTF8"
os.environ["TNS_ADMIN"] = r"C:\app\Mopa\product\21c\dbhomeXE\instantclient"

try:
    connection = oracledb.connect(
        user=os.getenv("ORACLE_USER", "HR"),
        password=os.getenv("ORACLE_PASSWORD", "HR"),
        dsn=os.getenv("ORACLE_DSN", "localhost/xepdb1")  # ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù€ SID Ø£Ùˆ Service Name
    )
    print("Successfully connected to Oracle database.")
except Exception as e:
    print(f"Error connecting to Oracle database: {e}")
    connection = None

# SQLAlchemy
# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ Service Name ÙÙŠ Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„
engine = create_engine(os.getenv("SQLALCHEMY_DATABASE_URI", "oracle+oracledb://HR:HR@localhost/?service_name=xepdb1"))
SessionLocal = sessionmaker(bind=engine)
metadata = MetaData(naming_convention={"skip_sorted_tables": True})
Base = declarative_base()

# Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
class User(Base):
    __tablename__ = 'users'
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String(50), unique=True, nullable=False)
    password = Column(String(255), nullable=False)

    # ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
class Conversation(Base):
    __tablename__ = 'conversations'
    conversation_id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)
    question = Column(Text, nullable=False)  # ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Text Ø£Ùˆ CLOB Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
    response = Column(Text, nullable=False)
    timestamp = Column(DateTime, default=datetime.utcnow)
    feedback = Column(Text)  # Ø­Ù‚Ù„ Ù†ØµÙŠ Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
    classification = Column(String(100))  # Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØµÙ†ÙŠÙ

    user = relationship("User", backref="conversations")

# ØªØ¹Ø±ÙŠÙ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
class Feedback(Base):
    __tablename__ = 'feedback'
    feedback_id = Column(Integer, primary_key=True, index=True)
    conversation_id = Column(Integer, ForeignKey('conversations.conversation_id'), nullable=False)
    rating_type = Column(Integer)  # ØªÙ‚ÙŠÙŠÙ… Ø±Ù‚Ù…ÙŠ Ù…Ø«Ù„Ù‹Ø§ Ù…Ù† 1 Ø¥Ù„Ù‰ 5
    comments = Column(Text)  # Ø­Ù‚Ù„ Ù†ØµÙŠ Ù„Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª

    conversation = relationship("Conversation", backref="feedbacks")


# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
Base.metadata.create_all(bind=engine)

# Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
lang_client = LangOpenAI(api_key=os.getenv("OPENAI_API_KEY"))



smtplib.debuglevel = 1


# Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (Logging)
logging.basicConfig(level=logging.ERROR , format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)



# Agent Base Class
class AgentBase:
    def __init__(self, name):
        self.name = name

    def process(self, input_data):
        raise NotImplementedError("This method should be implemented by subclasses.")

# InputAgent Class
class InputAgent(AgentBase):
    def __init__(self, name):
        super().__init__(name)
        self.llm = LangOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.prompt_template = PromptTemplate.from_template(
            "Based on the following database schema: {schema}\n"
            "Improve the following question for better understanding and context:\n"
            "Question: {question}\n"
            "Improved Question:"
        )

    def process(self, user_input):
        start_time = time.time()
        schema_info = self.get_database_schema()  # Get schema details
        logger.info(f"{self.name} received input: {user_input}")
        chain = LLMChain(llm=self.llm, prompt=self.prompt_template)
        improved_question = chain.run(schema=schema_info, question=user_input)
        elapsed_time = time.time() - start_time
        logger.info(f"{self.name} improved input: {improved_question} (Processed in {elapsed_time:.2f} seconds)")
        return improved_question.strip()

    def get_database_schema(self):
        return get_all_table_schemas()



# ====================================================================
# Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# ====================================================================
# Ø¥Ù†Ø´Ø§Ø¡ PromptTemplate Ø£Ø³Ø§Ø³ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙÙŠ Ø³Ù„Ø§Ø³Ù„ LangChain)
prompt_template = PromptTemplate.from_template(
    "Ù‚Ù… Ø¨ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚:\n"
    "Ø§Ù„Ø³ÙŠØ§Ù‚: {context}\n"
    "Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {query}\n"
    "Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£: {error_message}\n"
    "Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†:"
)
# Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø§Ù…Ù„ Ø§Ù„Ù€ pipe Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¥Ù„Ù‰ Runnable Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… lang_client
llm_chain = prompt_template | lang_client

def self_reflect_and_replan(query: str, error_message: str, context: dict) -> str:
    """
    ØªØ³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø³Ù„Ø³Ù„Ø© LLM Ù„Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚.
    """
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªØºÙŠØ± manual_prompt Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…ØªØºÙŠØ± ØºÙŠØ± Ù…Ø¹Ø±Ù
    escaped_context = str(context).replace("{", "{{").replace("}", "}}")
    manual_prompt = f"""
Ù„Ù‚Ø¯ ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„ØªØ§Ù„ÙŠ:
{query}

ÙˆÙ„ÙƒÙ† Ø¸Ù‡Ø±Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:
{error_message}

Ù…Ø¹ Ø§Ù„Ø¹Ù„Ù… Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚: {escaped_context}

Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø¹Ø¯Ù„ ÙŠØ£Ø®Ø° Ø¨Ø¹ÙŠÙ† Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± ØªØ­Ø³ÙŠÙ† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆØ£ÙŠ Ù…Ù‚ØªØ±Ø­Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡.
"""
    # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù€ prompt Ù…Ø¹ lang_client
    manual_chain = PromptTemplate.from_template(manual_prompt) | lang_client
    new_query = manual_chain.invoke({})
    return new_query.strip()

def is_response_satisfactory(response: str) -> bool:
    """
    ØªØªØ­Ù‚Ù‚ Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø±Ø¶ÙŠØ© (ØºÙŠØ± ÙØ§Ø±ØºØ© ÙˆÙ„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "error").
    """
    return bool(response.strip()) and "error" not in response.lower()

def auto_recursive_reasoning(prompt: str, max_depth=3, current_depth=0) -> str:
    """
    ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ¯Ù„Ø§Ù„ ØªÙƒØ±Ø§Ø±ÙŠ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©Ø› Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± Ù…Ø±Ø¶ÙŠØ© ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ù€ prompt
    ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø­ØªÙ‰ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¬ÙŠØ¯Ø© Ø£Ùˆ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª.
    ÙŠÙ‚ÙˆÙ… Ø§Ù„ÙƒÙˆØ¯ Ø¨Ù‡Ø±ÙˆØ¨ Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ ÙÙŠ prompt Ù„ØªØ¬Ù†Ø¨ ØªÙØ³ÙŠØ±Ù‡Ø§ ÙƒÙ…ØªØºÙŠØ±Ø§Øª.
    """
    escaped_prompt = prompt.replace("{", "{{").replace("}", "}}")
    chain = PromptTemplate.from_template(escaped_prompt) | lang_client
    response = chain.invoke({})
    if is_response_satisfactory(response) or current_depth >= max_depth:
        return response.strip()
    else:
        new_prompt = f"Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ­Ø³Ù†Ù‡Ø§:\n{response}\nÙ…Ø¹ Ø§Ù„Ø£Ø®Ø° ÙÙŠ Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø±: {prompt}"
        return auto_recursive_reasoning(new_prompt, max_depth, current_depth + 1)


def generate_empty_result_response(question: str) -> str:
    """
    ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø·Ø¨ÙŠØ¹ÙŠ Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙØ±Ø¬Ø¹ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… DataFrame ÙØ§Ø±Øº.
    ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø§Ù„Ø© Ø¨Ø¥Ø±Ø³Ø§Ù„ prompt Ø¥Ù„Ù‰ ChatGPT Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ø§Ù…Ø© 
    ØªÙØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø·Ø§Ø¨Ù‚Ø©ØŒ Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø³Ù…Ø§Ø¡ Ø­Ù‚ÙˆÙ„ Ø«Ø§Ø¨ØªØ© ÙˆØ¨ØµÙŠØºØ© Markdown.
    """
    prompt = f"""
You are a data analyst assistant. The SQL query executed for the question:
"{question}"
returned no results.

Based on the analysis of the question and historical trends, please provide a clear, concise, 
and natural language response in markdown format explaining that there are no matching records.
Do not include any specific field names or fixed data; instead, give a general explanation and any 
possible insights that might help the user.
"""
    # Ù†Ø³ØªØ®Ø¯Ù… Ø¹Ù…ÙŠÙ„ OpenAI Ø§Ù„Ø£ØµÙ„ÙŠ ÙƒÙ…Ø§ Ù‡Ùˆ (client) Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ chat completions
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "developer", "content": "You are a helpful data analyst."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()




def execute_sql_with_iterative_refinement(query, max_retries=5):
    """
    ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ù…Ø¹ ØªØ­Ø³ÙŠÙ† ØªÙƒØ±Ø§Ø±ÙŠ (Iterative Query Refinement) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ.
    ØªÙØ¯Ù…Ø¬ Ø§Ù„Ø¯ÙˆØ§Ù„:
      - self_reflect_and_replan: Ù„Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù†Ø¯ ÙˆÙ‚ÙˆØ¹ Ø®Ø·Ø£.
      - is_response_satisfactory: Ù„ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†Ø© Ø¬ÙŠØ¯Ø©.
      - auto_recursive_reasoning: Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.
    
    Ø¥Ø°Ø§ ÙØ´Ù„Øª ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØªÙØ¹Ø§Ø¯ DataFrame ÙØ§Ø±Øº.
    """
    current_query = query
    # Ù†ÙØªØ±Ø¶ Ø£Ù† get_all_table_schemas() Ù…ÙØ¹Ø±ÙØ© ÙˆØªÙØ¹ÙŠØ¯ ÙˆØµÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
    context = {"schema": get_all_table_schemas()}
    attempt = 0
    error_message = ""
    
    while attempt < max_retries:
        try:
            df = execute_sql_query(current_query)
            if df is not None and not df.empty:
                return df
        except Exception as e:
            error_message = str(e)
            logging.error(f"Attempt {attempt+1} failed with error: {error_message}")
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… self_reflect_and_replan
        refined_query = self_reflect_and_replan(current_query, error_message, context)
        # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙØ­Ø³Ù†Ø© Ù…Ø±Ø¶ÙŠØ©ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… auto_recursive_reasoning Ù„ØªØ­Ø³ÙŠÙ†Ù‡Ø§
        if not is_response_satisfactory(refined_query):
            refined_query = auto_recursive_reasoning(refined_query, max_depth=3)
        
        current_query = refined_query
        logging.info(f"Retrying with refined query (attempt {attempt+1}/{max_retries}): {current_query}")
        attempt += 1
    
    # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ø³ØªÙ†ÙØ§Ø° Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§ØªØŒ Ù†Ø¬Ø±Ø¨ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø±Ø© Ø£Ø®ÙŠØ±Ø©Ø› ÙˆØ¥Ù† ÙØ´Ù„ Ù†ÙØ¹ÙŠØ¯ DataFrame ÙØ§Ø±Øº
    try:
        df = execute_sql_query(current_query)
        return df if df is not None else pd.DataFrame()
    except Exception as final_e:
        logging.error(f"Final attempt failed: {final_e}")
        return pd.DataFrame()



import json

def save_conversation(user_id, question, answer, classification, feedback=None):
    try:
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ ÙƒØ§Ø¦Ù† JSON
        conversation_data = {
            "question": question,
            "answer": answer,
            "classification": classification
        }

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù† Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© JSON
        response_json = json.dumps(conversation_data, ensure_ascii=False)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        db_session = SessionLocal()
        new_conversation = Conversation(
            user_id=user_id,
            question=question,  # ÙŠÙ…ÙƒÙ† Ø­Ø°Ù Ù‡Ø°Ø§ Ø§Ù„Ø­Ù‚Ù„ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø­ÙØ¸ ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ `response`
            response=response_json,  # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙƒÙ€ JSON
            feedback=feedback,
            classification=classification
        )
        db_session.add(new_conversation)
        db_session.commit()
        db_session.refresh(new_conversation)
        db_session.close()

        # Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        return new_conversation.conversation_id
    except Exception as e:
        print(f"Error saving conversation: {e}")
        if db_session:
            db_session.rollback()
            db_session.close()
        return None


import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

def fetch_all_data():
    db_session = SessionLocal()
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
    conversations = db_session.query(Conversation).all()
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
    feedbacks = db_session.query(Feedback).all()
    db_session.close()

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³
    conv_data = [{
        "conversation_id": conv.conversation_id,
        "user_id": conv.user_id,
        "question": conv.question,
        "response": conv.response,
        "timestamp": conv.timestamp,
        "feedback": conv.feedback
    } for conv in conversations]

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³
    feedback_data = [{
        "feedback_id": fb.feedback_id,
        "conversation_id": fb.conversation_id,
        "rating_type": fb.rating_type,
        "comments": fb.comments
    } for fb in feedbacks]

    return conv_data, feedback_data

def analyze_question_patterns():
    conv_data, _ = fetch_all_data()
    df_conversations = pd.DataFrame(conv_data)

    # ØªØ¬Ù‡ÙŠØ² Ù†Øµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡Ø§Øª
    vectorizer = TfidfVectorizer(stop_words='arabic')
    X = vectorizer.fit_transform(df_conversations['question'].astype(str))

    # ØªØ·Ø¨ÙŠÙ‚ KMeans Ù„Ù„ØªØ¬Ù…ÙŠØ¹
    n_clusters = 5
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X)

    df_conversations['cluster'] = kmeans.labels_
    pattern_counts = df_conversations['cluster'].value_counts()
    print("Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹:\n", pattern_counts)


# Ø¯Ø§Ù„Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨ØµÙŠØºØ© HTML
def send_email_html(to_addresses, subject, html_body, smtp_server="apexexperts.net", smtp_port=465, username="ai@apexexperts.net", password="Ahmed@_240615"):
    msg = MIMEText(html_body, "html", "utf-8")
    msg = MIMEMultipart()
    msg["Subject"] = subject
    msg["From"] = username
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ Ù‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¹Ù‡Ø§ Ù„Ø±Ø£Ø³ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
    if isinstance(to_addresses, list):
        msg["To"] = ", ".join(to_addresses)
    else:
        msg["To"] = to_addresses
    msg.attach(MIMEText(html_body, "html", "utf-8"))
    try:
        server = smtplib.SMTP_SSL(smtp_server, smtp_port)
        server.login(username, password)
        server.sendmail(username, to_addresses if isinstance(to_addresses, list) else [to_addresses], msg.as_string())
        server.quit()
        return True
    except Exception as e:
        print(f"Error sending email: {e}")
        return False

def send_weekly_report():
    subject = "Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ"
    body = "<h1>Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ</h1><p>Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ.</p>"
    to_email = "ahmed-alsaied@msn.com"
    send_email_html(to_email, subject, body)

def send_weekly_report_with_chart():
    logger.info("Running send_weekly_report_with_chart...")
    subject = "Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ù…Ø¹ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ"
    body = "<h1>Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ</h1><p>Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ.</p>"
    to_email = "recipient@example.com"
    send_email_html(to_email, subject, body)

def dicts_to_html_table(data):
    if not data:
        return "<p>Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª.</p>"
    
    df = pd.DataFrame(data)
    html_table = df.to_html(classes="min-w-full bg-white border border-blue-200 rounded-lg text-center", index=False)
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tailwind CSS
    styled_table = f"""
    <div class="overflow-x-auto">
        {html_table}
    </div>
    """
    return styled_table


def get_all_table_schemas():
    if not connection:
        print("No database connection.")
        return ""
    try:
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT TABLE_NAME, COLUMN_NAME, DATA_TYPE
                FROM ALL_TAB_COLUMNS
                WHERE OWNER = 'HR'
                ORDER BY TABLE_NAME, COLUMN_ID
            """)
            rows = cursor.fetchall()
        table_schemas = {}
        for row in rows:
            table, column, data_type = row
            if table not in table_schemas:
                table_schemas[table] = []
            table_schemas[table].append(f"{column} ({data_type})")
        schema_summary = ""
        for table, columns in table_schemas.items():
            schema_summary += f"\nTable {table} has the following columns:\n"
            for col in columns:
                schema_summary += f"- {col}\n"
        return schema_summary
    except Exception as e:
        print(f"Error fetching table schemas: {e}")
        return ""
    
def get_ddl_for_table(table_name):
    """
    ØªØ³ØªØ®Ø±Ø¬ DDL Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ÙŠÙ† ÙˆØªÙ†Ø³ÙŠÙ‚Ù‡ ÙƒÙƒÙˆØ¯ SQL.
    """
    sql_query = f"SELECT DBMS_METADATA.GET_DDL('TABLE', '{table_name.upper()}') AS DDL FROM DUAL"
    df = execute_sql_with_iterative_refinement(sql_query, max_retries=5)
    
    if df is not None and not df.empty:
        ddl_text = df['DDL'].iloc[0]
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ…Ù‚Ø·Ø¹ ÙƒÙˆØ¯ SQL Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
        cleaned_ddl = "\n".join([line for line in ddl_text.split("\n") if line.strip() != ""])
        return f"```sql\n{cleaned_ddl}\n```"
    else:
        return None


def classify_question(question):
    """
    ÙŠØµÙ†Ù Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø£Ø­Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©:
    - 'db_sql'    : Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ø¹Ø§Ø¯ÙŠ (SELECT)
    - 'db_analysis': ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…/Ø¥Ø­ØµØ§Ø¦ÙŠ
    - 'db_action' : Ø£ÙˆØ§Ù…Ø± ØªØ¹Ø¯ÙŠÙ„ (INSERT / UPDATE / DELETE)
    - 'general'   : Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…
    """

    question_lower = question.lower().strip()

    # ===== Ù…ÙØ§ØªÙŠØ­ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (Action) =====
    action_keywords = [
        "insert", "update", "delete", "remove", "add", "create record", "create table",
        "send mail", "create restful services",
        "drop", "truncate", "Ø§Ù†Ø´Ø§Ø¡", "Ø¥Ø¶Ø§ÙØ©", "Ø­Ø°Ù", "ØªØ­Ø¯ÙŠØ«", 
        "ØªØ¹Ø¯ÙŠÙ„", "add column", "rename"
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ ØªØ­Ù„ÙŠÙ„ÙŠØ© (Analysis) =====
    analysis_keywords = [
        "ØªØ­Ù„ÙŠÙ„", "Ø§Ø­ØµØ§Ø¡", "Ø¥Ø­ØµØ§Ø¡", "Ø¥Ø­ØµØ§Ø¦ÙŠ","Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ"
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ SQL (Reading) =====
    db_sql_keywords = [
        "select", "show me", "fetch", "retrieve","pivot"
        "Ø§Ø³ØªØ¹Ù„Ø§Ù…", "query", "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„", "Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©",
        "sum", "Ù…Ø¬Ù…ÙˆØ¹", "Ø§Ø¬Ù…Ø§Ù„ÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ", "Ù…ØªÙˆØ³Ø·",
        "maximum", "minimum", "order by", "limit",
        "Ø¹Ø±Ø¶", "Ø§Ø¸Ù‡Ø§Ø±", "   "
    ]

    # ===== Ù…ÙØ§ØªÙŠØ­ Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø© (General) =====
    general_keywords = [
        "what is", "explain", "why", "how to", "ÙƒÙŠÙÙŠØ©",
        "Ø¹Ø§Ù…", "Ù…Ø¹Ù„ÙˆÙ…Ø©", "what are", "Ù…ØªÙ‰", "Ø£ÙŠÙ†", "Ù„Ù…Ø§Ø°Ø§"
    ]

    # 1) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ action_keywords
    for ak in action_keywords:
        if ak in question_lower:
            print("Local classification => db_action")
            return "db_action"

    # 2) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ analysis
    for kw in analysis_keywords:
        if kw in question_lower:
            print("Local classification => db_analysis")
            return "db_analysis"

    # 3) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ db_sql
    for kw in db_sql_keywords:
        if kw in question_lower:
            print("Local classification => db_sql")
            return "db_sql"

    # 4) Ù„Ùˆ Ø±ØµØ¯Ù†Ø§ general_keywords
    for kw in general_keywords:
        if kw in question_lower:
            print("Local classification => general")
            return "general"

    # 5) Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¹Ø«Ø± Ø¹Ù„Ù‰ ØªØµÙ†ÙŠÙ ÙˆØ§Ø¶Ø­ Ù…Ø­Ù„ÙŠÙ‹Ø§ => Ù†Ù„Ø¬Ø£ Ù„Ù€GPT
    try:
        schema_summary = get_all_table_schemas()  # ÙŠÙØªØ±Ø¶ Ø£Ù†Ù‡Ø§ Ø¯Ø§Ù„Ø© Ù„Ø¯ÙŠÙƒ ØªØ¹ÙŠØ¯ ÙˆØµÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        prompt = f"""
You are a classification assistant. You have the following database schema:

{schema_summary}

You must classify any user question into exactly one category:
1) db_sql: direct query about the database, e.g. SELECT, pivot table retrieving rows/columns directly, "Show me employees"
2) db_analysis: advanced analysis or statistics on the data, e.g. "Calculate average salary or distribution"
3) db_action: modifying the database, e.g. "INSERT, UPDATE, DELETE, DROP, CREATE TABLE"
4) general: if not related to the HR database or no direct data/analysis request.

Important rules:
- If user question includes "INSERT", "UPDATE", "DELETE", "CREATE", "DROP", or similar, classify as db_action.
- If user question includes "mean, distribution, correlation, statistic", or advanced analysis terms, classify as db_analysis.
- If user question includes "select, show me, fetch, retrieve" from a table, or direct request of rows, classify as db_sql.
- If user question is unrelated to the HR schema, or is general knowledge, classify as general.
- Use EXACT category name: db_sql, db_analysis, db_action, or general. No extra words.

Examples:
1) "Add new column to EMPLOYEES" => db_action
2) "Compute average salary of employees" => db_analysis
3) "SELECT * from employees" => db_sql
4) "What is AI?" => general

Now, classify the user question below:

Question: "{question}"
Answer with exactly one of: db_sql, db_analysis, db_action, or general.
"""
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "developer", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ]
        )
        classification = response.choices[0].message.content.strip().lower()
        print(f"GPT classification => {classification}")

        if 'db_sql' in classification:
            return 'db_sql'
        elif 'db_analysis' in classification:
            return 'db_analysis'
        elif 'db_action' in classification:
            return 'db_action'
        else:
            return 'general'
    except Exception as e:
        print(f"Error classifying question with GPT: {e}")
        return 'general'

def translate_ar_to_en(text):
    try:
        print("Translating:", text)
        translated = GoogleTranslator(source='ar', target='en').translate(text)
        print("Translated:", translated)
        return translated
    except Exception as e:
        print(f"Translation error: {e}")
        return text

def clean_sql_query(sql_query):
    sql_query = sql_query.strip()
    sql_query = re.sub(r';$', '', sql_query)
    sql_query = re.sub(r'[Ø›Ø›]', '', sql_query)
    sql_query = sql_query.replace('\u200f', '')
    return sql_query

def natural_language_to_sql(question, is_chart=False, improved_question=None):
    """
    ÙŠØ­ÙˆÙ„ Ø£Ø³Ø¦Ù„Ø© ØªØªØ¹Ù„Ù‚ Ø¨Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (SELECT) Ø¥Ù„Ù‰ Ø¬Ù…Ù„Ø© SQL.
    """
    try:
        question_to_use = improved_question if improved_question else translate_ar_to_en(question)
        schema_summary = get_all_table_schemas()

        if is_chart:
            prompt = f"""
Translate the following question into a SQL query that returns data suitable for a bar chart with two columns: 'label' and 'value'. Provide only the SQL code without any explanations or additional text. Do not include a semicolon at the end.

Here is the schema of the database:
{schema_summary}

Question: '{question_to_use}'
"""
        else:
            prompt = f"""
Translate the following question into a SQL query. Provide only the SQL code without any explanations or additional text. Do not include a semicolon at the end.

Here is the schema of the database:
{schema_summary}

Question: '{question_to_use}'
"""

        print(f"Sending prompt to OpenAI: {prompt}")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "developer", "content": "You are a helpful assistant that translates natural language questions into SQL queries compatible with Oracle Database."},
                {"role": "user", "content": prompt}
            ]
        )
        sql_query = response.choices[0].message.content.strip()
        print(f"Generated SQL Query: {sql_query}")
        return clean_sql_query(sql_query)
    except Exception as e:
        print(f"Error generating SQL query: {e}")
        return None

def natural_language_to_dml_action(question):
    """
    ÙŠØ­ÙˆÙ‘Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ (INSERT/UPDATE/DELETE)
    Ø¥Ù„Ù‰ Ø¬Ù…Ù„Ø© SQL Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£ÙƒØ´Ù†.
    """
    try:
        question_en = translate_ar_to_en(question)
        schema_summary = get_all_table_schemas()

        prompt = f"""
You are an Oracle database expert. Always generate valid Oracle syntax, with the ability to execute any complex queries, as well as add, modify, and delete data. You have complete knowledge of all tables and data in the database and can provide effective solutions to any database-related issues. Your tasks include:

Executing complex SQL queries:

Do not use multi-row insert with VALUES (...),(...) style.

Use either multiple INSERT statements or the Oracle INSERT ALL syntax. 

Writing queries to extract required data from tables.

Using JOIN, GROUP BY, HAVING, SUBQUERIES, and other advanced operations.

Optimizing queries to ensure optimal performance.

Managing data:

Adding new data to tables using INSERT.

Updating existing data using UPDATE.

Deleting data using DELETE.

Analyzing data:

Analyzing relationships between tables and understanding the database structure.

Identifying data issues and providing solutions to fix them.

Creating and modifying tables:

Creating new tables using CREATE TABLE.

Modifying table structures using ALTER TABLE.

Dropping tables using DROP TABLE.

Managing indexes:

Creating indexes to improve query performance.

Analyzing existing indexes and determining the need for modifications.

Providing reports and results:

Delivering clear and organized results for queries.

Generating reports summarizing the required data.

Troubleshooting:

Analyzing errors in queries and fixing them.

Providing solutions for any issues related to data integrity or performance.

You are familiar with all tables, columns, and relationships between them, and you can provide accurate and effective answers to any questions or requests related to Oracle databases.

Database schema:
{schema_summary}

User request: '{question_en}'
"""

        print(f"Sending 'action' prompt to OpenAI:\n{prompt}")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "developer", "content": "You are an assistant that writes Oracle-compatible DML statements."},
                {"role": "user", "content": prompt}
            ]
        )
        action_sql = response.choices[0].message.content.strip()
        print(f"Generated DML SQL: {action_sql}")
        return clean_sql_query(action_sql)
    except Exception as e:
        print(f"Error generating DML action: {e}")
        return None

def execute_sql_query(sql_query):
    """
    ÙŠÙ†ÙÙ‘Ø° Ø§Ø³ØªØ¹Ù„Ø§Ù… SELECT Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ¹ÙŠØ¯ DataFrame.
    """
    if not connection:
        print("No database connection.")
        return None
    try:
        with connection.cursor() as cursor:
            print(f"Executing SQL Query: {sql_query}")
            cursor.execute(sql_query)
            rows = cursor.fetchall()
            
            # ØªØ­ÙˆÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ù†ÙˆØ¹ CLOB Ø¥Ù„Ù‰ Ù†Øµ Ø¹Ø§Ø¯ÙŠ
            processed_rows = []
            for row in rows:
                processed_row = []
                for col in row:
                    if isinstance(col, oracledb.LOB):
                        processed_row.append(str(col.read()))
                    else:
                        processed_row.append(str(col) if col is not None else "")
                processed_rows.append(processed_row)
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            columns = [desc[0] for desc in cursor.description]
            
            # Ø¥Ù†Ø´Ø§Ø¡ DataFrame
            df = pd.DataFrame(processed_rows, columns=columns)
            df = df.fillna("")
            
            # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df.columns = [col.replace(" ", "_").upper() for col in df.columns]
            
            print(f"Query Results:\n{df.to_string(index=False)}")
            return df
    except Exception as e:
        print(f"Error executing SQL query: {e}")
        return None

def execute_sql_action(sql_statement):
    """
    ÙŠÙ†ÙÙ‘Ø° (INSERT / UPDATE / DELETE / PL/SQL) Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ¹Ù…Ù„ commit.
    ÙŠØ¹ÙŠØ¯ (success, message, rows_affected).
    """
    if not connection:
        print("No database connection.")
        return False, "No DB connection", 0
    
    try:
        with connection.cursor() as cursor:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
            cleaned_sql = sql_statement.strip()
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù†Øµ ØºÙŠØ± SQL (Ù…Ø«Ù„ Ø§Ù„Ø´Ø±ÙˆØ­Ø§Øª)
            if "```sql" in cleaned_sql:
                cleaned_sql = cleaned_sql.split("```sql")[1].split("```")[0].strip()
            elif "```" in cleaned_sql:
                cleaned_sql = cleaned_sql.split("```")[1].strip()
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ÙÙˆØ§ØµÙ„ Ù…Ù†Ù‚ÙˆØ·Ø© (;) ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
            cleaned_sql = cleaned_sql.rstrip(';')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù…Ø³Ø§ÙØ§Øª Ø²Ø§Ø¦Ø¯Ø©
            cleaned_sql = ' '.join(cleaned_sql.split())
            
            print(f"Executing SQL Action: {cleaned_sql}")
            
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† PL/SQL
            is_plsql = cleaned_sql.lower().startswith(("begin", "declare"))
            
            if is_plsql:
                # ØªÙ†ÙÙŠØ° ÙƒØªÙ„Ø© PL/SQL
                cursor.execute(cleaned_sql)
                rows_affected = 0  # PL/SQL Ù„Ø§ ÙŠØ¹ÙŠØ¯ Ø¹Ø¯Ø¯ Affected rows
            else:
                # ØªÙ†ÙÙŠØ° SQL Ø¹Ø§Ø¯ÙŠ
                cursor.execute(cleaned_sql)
                rows_affected = cursor.rowcount  # Ø¹Ø¯Ø¯ Affected rows
            
            connection.commit()
            return True, "ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­", rows_affected
    except Exception as e:
        print(f"Error executing SQL action: {e}")
        return False, str(e), 0

def get_salary_summary():
    """
    Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·: Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙŠÙØ¹ÙŠØ¯ (MIN(SALARY), MAX(SALARY), AVG(SALARY), COUNT(*))
    ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ù…Ø§ ØªØ±ÙŠØ¯ ØªÙ„Ø®ÙŠØµÙ‡.
    """
    if not connection:
        return {}
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT MIN(SALARY), MAX(SALARY), AVG(SALARY), COUNT(*) FROM EMPLOYEES")
            row = cursor.fetchone()
            if row:
                min_sal, max_sal, avg_sal, cnt = row
                return {
                    "min_salary": float(min_sal or 0),
                    "max_salary": float(max_sal or 0),
                    "avg_salary": float(avg_sal or 0),
                    "total_employees": int(cnt or 0)
                }
    except:
        pass
    return {}

def generate_chart(data, x_key, y_key):
    plt.figure(figsize=(10, 6))
    plt.bar(data[x_key], data[y_key], color='skyblue')
    plt.xlabel(x_key)
    plt.ylabel(y_key)
    plt.title(f"Sum of {y_key} by {x_key}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    chart_path = f"./static/charts/{uuid.uuid4().hex}.png"
    os.makedirs(os.path.dirname(chart_path), exist_ok=True)
    plt.savefig(chart_path)
    plt.close()
    return f"./static/charts/{os.path.basename(chart_path)}"

def remove_markdown_fences(code_text):
    code_text = re.sub(r"```python\s*", "", code_text)
    code_text = re.sub(r"```", "", code_text)
    return code_text

def exec_python_code(code, df):
    code = remove_markdown_fences(code)

    old_stdout = sys.stdout
    mystdout = io.StringIO()
    sys.stdout = mystdout

    local_env = {
        "df": df,
        "pd": pd,
        "np": np,
        "plt": plt
    }

    try:
        exec(code, local_env)
    except Exception as e:
        sys.stdout = old_stdout
        error_output = mystdout.getvalue()
        tb = traceback.format_exc()
        error_output += f"\n\nØ­Ø¯Ø« Ø§Ø³ØªØ«Ù†Ø§Ø¡:\n{str(e)}\nTraceback:\n{tb}"
        return f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙˆØ¯:\n{error_output}", ""

    output = mystdout.getvalue()
    sys.stdout = old_stdout
    return "", output


def generate_response_with_context(question):
    conversation_history = session.get('conversation_history', [])
    context = " ".join([msg["content"] for msg in conversation_history])
    prompt = f"Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ: {context}\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "developer", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

import json
from langdetect import detect, LangDetectException
from openai import ChatCompletion

def generate_summary(output, question):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
    """
    # Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„
    try:
        language = detect(question)
    except LangDetectException:
        language = 'en'

    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø¥Ù„Ù‰ JSON
        data = json.loads(output)
        labels = data.get("labels", [])
        values = data.get("values", [])

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if not labels or not values or len(labels) != len(values):
            return "Cannot generate summary due to data mismatch." if language != 'ar' else "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Øµ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        prompt = f"""
        You are a data analyst assistant. Analyze the following data and generate a dynamic summary in the same language as the user's question:

        - Question: "{question}"
        - Data Labels: {labels}
        - Data Values: {values}

        Your summary should include:
        - Key insights based on the data (e.g., highest value, lowest value, total, averages, trends, etc.).
        - Provide actionable recommendations if applicable.
        - Write the summary in the same language as the user's question.

        Output the result in plain text.
        """

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ OpenAI API
        response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "developer", "content": "You are an advanced data analyst capable of generating insights dynamically."},
            {"role": "user", "content": prompt}
        ]
    )
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        summary = response.choices[0].message.content.strip()

                # Ø¥Ø¶Ø§ÙØ© Ø§ØªØ¬Ø§Ù‡ RTL Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ©
        if language == 'ar':
            rtl_mark = "\u202B"  # Ø¹Ù„Ø§Ù…Ø© Ø¨Ø¯Ø¡ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±
            rtl_reset = "\u202C"  # Ø¹Ù„Ø§Ù…Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ
            summary = f"{rtl_mark}{summary}{rtl_reset}"

        return summary

    except json.JSONDecodeError:
        return "Unable to interpret analysis output." if language != 'ar' else "ØªØ¹Ø°Ø± ØªÙØ³ÙŠØ± Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„."
    except Exception as e:
        return f"Error in generating summary: {str(e)}"

    
# ====================================================================
#             Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# ====================================================================

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/register', methods=['POST'])
def register_user():
    try:
        data = request.get_json()
        username = data.get("username")
        password = data.get("password")
        if not username or not password:
            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"}), 400

        db = SessionLocal()
        existing_user = db.query(User).filter(User.username == username).first()
        if existing_user:
            return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„"}), 400

        hashed_password = generate_password_hash(password)
        new_user = User(username=username, password=hashed_password)
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        db.close()

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        session['username'] = username
        session['session_id'] = str(uuid.uuid4())
        session['conversation_history'] = []
        session['memory'] = {}

        return jsonify({"message": f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username} Ø¨Ù†Ø¬Ø§Ø­!"}), 201
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/login', methods=['POST'])
def login_user():
    try:
        data = request.get_json()
        username = data.get("username")
        password = data.get("password")
        if not username or not password:
            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"}), 400

        db = SessionLocal()
        user = db.query(User).filter(User.username == username).first()
        if not user or not check_password_hash(user.password, password):
            return jsonify({"error": "Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©"}), 401

        db.close()

        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¬Ù„Ø³Ø©
        session['username'] = username
        session['session_id'] = str(uuid.uuid4())
        session['conversation_history'] = []
        session['memory'] = {}

        return jsonify({"message": f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙƒÙ€ {username}!"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/logout', methods=['POST'])
def logout():
    try:
        session.clear()
        return jsonify({"message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¨Ù†Ø¬Ø§Ø­. ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ù€ Cookies"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500




@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        username = data.get('username')
        question = data.get('question')

        if not username:
            return jsonify({'error': 'Username is required.'}), 400
        if 'username' not in session or session['username'] != username:
            return jsonify({'error': 'User not logged in.'}), 401
        if not question:
            return jsonify({'error': 'No question provided'}), 400
            
            
        user = SessionLocal().query(User).filter(User.username == username).first()
        if not user:
            return jsonify({'error': 'User not found.'}), 404

        input_agent = InputAgent("InputAgent")
        improved_question = input_agent.process(question)

        question_lower = improved_question.lower()

        # ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ `answer`
        answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„."

        classification = classify_question(question)
        print(f"Question classification: {classification}")

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµÙŠØ© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
        if ("send mail" in question_lower or 
            "send an email" in question_lower or 
            "Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯" in question_lower or 
            "Ø§Ø±Ø³Ù„ Ø¨Ø±ÙŠØ¯" in question_lower):

            emails = []   

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
            if "all employees" in question_lower or "ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†" in question_lower:
                query = "SELECT EMAIL FROM EMPLOYEES"
                df_emails = execute_sql_with_iterative_refinement(query, max_retries=5)
                if df_emails is not None and not df_emails.empty:
                    emails = df_emails['EMAIL'].dropna().tolist()

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ù„ÙƒÙ„ Ù…Ù† ÙŠØ¹Ù…Ù„ Ø¨ÙˆØ¸ÙŠÙØ© Ù…Ø¹ÙŠÙ†Ø©
            elif "job" in question_lower or "ÙˆØ¸ÙŠÙØ©" in question_lower:
                job_match = re.search(r'ÙˆØ¸ÙŠÙØ©\s+(\w+)', question_lower)
                if job_match:
                    job_title = job_match.group(1)
                    query = f"SELECT EMAIL FROM EMPLOYEES WHERE LOWER(JOB_ID) LIKE '%{job_title.lower()}%'"
                    df_emails = execute_sql_with_iterative_refinement(query, max_retries=5)
                    if df_emails is not None and not df_emails.empty:
                        emails = df_emails['EMAIL'].dropna().tolist()

            # Ø­Ø§Ù„Ø©: Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„Ù‰ Ù…ÙˆØ¸Ù Ù…Ø­Ø¯Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£ÙˆÙ„ Ø£Ùˆ Ø§Ù„Ø£Ø®ÙŠØ±
            else:
                name_match = re.search(r'Ø§Ù„Ù‰\s+(\w+)', question_lower)
                recipient_name = name_match.group(1) if name_match else None

                if recipient_name:
                    query = f"""
                    SELECT EMAIL FROM EMPLOYEES 
                    WHERE LOWER(FIRST_NAME) = '{recipient_name.lower()}'
                    OR LOWER(LAST_NAME) = '{recipient_name.lower()}'
                    """
                    df_emails = execute_sql_with_iterative_refinement(query, max_retries=5)
                    if df_emails is not None and not df_emails.empty:
                        emails = df_emails['EMAIL'].dropna().tolist()

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
            if not emails:
                return jsonify({"error": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ù„Ù…Ø³ØªÙ„Ù…ÙŠÙ†."}), 400

            # ØªÙ†Ø¸ÙŠÙ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­ØªÙ‡Ø§
            emails = [email.strip() for email in emails if email.strip()]
            recipients_str = ", ".join(emails)

            conversation_history = session.get('conversation_history', [])
            last_assistant_msg = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø³Ø§Ø¨Ù‚Ø©."
            last_assistant_data = None  # Ø³Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©

            if conversation_history:
                for msg in reversed(conversation_history):
                    if msg.get('role') == 'assistant' and msg.get('content'):
                        last_assistant_msg = msg['content']
                        break

            html_body = f"""
            <html>
            <body>
                <h2>Ù…Ø±Ø³Ù„ Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ğŸ˜Š</h2>
                <p>Ù…Ø±Ø­Ø¨Ù‹Ø§ØŒ</p>
                <p>Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:</p>
                <pre>{last_assistant_msg}</pre>
            </body>
            </html>
            """
            subject = "Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ğŸ˜Š"

            email_sent = send_email_html(emails, subject, html_body)
            if email_sent:
                # ØªØ­Ø¯ÙŠØ« ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {recipients_str} ğŸ˜Š."})
                session['conversation_history'] = conversation_history

                return jsonify({
                    "results": [{"answer": f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {recipients_str} ğŸ˜Š."}],
                    "classification": "email"
                }), 200
            else:
                return jsonify({"error": "ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯."}), 500

        # =============== GENERAL ===============
        if classification == 'general':
            conversation_history = session.get('conversation_history', [])
            system_content = "You are a helpful assistant."
            if 'assistant_name' in session.get('memory', {}):
                assistant_name = session['memory']['assistant_name']
                system_content = f"You are {assistant_name}, a helpful assistant."

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "developer", "content": system_content},
                        *conversation_history,
                        {"role": "user", "content": question}
                    ]
                )
                answer = response.choices[0].message.content.strip()
            except Exception as e:
                print(f"Error in GPT response: {e}")
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

            # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            user = SessionLocal().query(User).filter(User.username == username).first()
            conv_id = None
            if user:
                conv_id = save_conversation(user.id, question, answer, classification='general')

            conversation_history.append({"role": "user", "content": question})
            conversation_history.append({"role": "assistant", "content": answer})
            session['conversation_history'] = conversation_history

            return jsonify({
                            'results': [{'answer': answer}],
                            'assistant_answer': answer,  # <-- Ø£Ø¶Ù Ù‡Ø°Ø§
                            'classification': 'general',
                            'conversation_id': conv_id
                        })



        # =============== DB_ANALYSIS ===============
        if classification == 'db_analysis':
            translated_en = translate_ar_to_en(question).lower()
            is_chart = any(word in translated_en for word in ["statistics", "chart", "graph", "plot"])
            base_sql = natural_language_to_sql(        question=question,
                                                        is_chart=is_chart,
                                                        improved_question=improved_question)
            if not base_sql:
                return jsonify({'error': 'ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.'}), 500
            
                    # ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
            df = execute_sql_with_iterative_refinement(base_sql, max_retries=5)

            
            if df is None or df.empty:
                    empty_answer = generate_empty_result_response(question)
                    # ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:
                    conv_id = save_conversation(user.id, question, empty_answer, classification='empty')
                    return jsonify({
                        'assistant_answer': empty_answer,
                        'classification': 'empty',
                        'conversation_id': conv_id
                      })

            df = df.fillna(0)
            columns_list = list(df.columns)
            sample_records = df.head(20).fillna(0).to_dict(orient='records')

            analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¨Ø§ÙŠØ«ÙˆÙ†. Ù„Ø¯ÙŠÙ†Ø§ DataFrame Ø¨Ø§Ø³Ù… df ÙŠØ­ÙˆÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:
{columns_list}

Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{sample_records}

Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ: "{question}"

*** Ù‡Ø§Ù… ***:
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Ø³Ù„Ø³Ù„Ø© Ù…Ø«Ù„ % Ø£Ùˆ f-string Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù†Ø§Øª Ù…Ø¹Ù‚Ù‘Ø¯Ø©.
- Ø§Ø³ØªØ®Ø¯Ù… json.dumps() Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø´ÙƒÙ„ JSON.
- **ÙŠØ¬Ø¨** Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø®Ø±Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ Ø´ÙƒÙ„:
  result = {{
    "labels": [...],   # Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ø£Ùˆ Ø§Ø³Ù…Ù‡ department_id Ø£Ùˆ city Ø£Ùˆ ... 
    "values": [...]    # Ø£ÙŠ Ù…Ø¬Ù…ÙˆØ¹/Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ø§Ø³Ù…Ù‡ total_salary Ø£Ùˆ salary ...
  }}
  - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØªØ·Ù„Ø¨ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…ÙƒØ¯Ø³ (Ù…Ø«Ù„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§ØªØ¨ ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†)ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…ÙƒØ¯Ø³ .
- Ø§Ø³ØªØ®Ø¯Ù… print(json.dumps(result)) Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
print(json.dumps(result))

(Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ù…ÙØ§ØªÙŠØ­ Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ department_id Ø£Ùˆ total_salary.)

Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Ø¨Ø§ÙŠØ«ÙˆÙ† ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø¹Ù„Ø§Ù…Ø§Øª ```python) Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¹Ù„Ù‰ df. Ø§Ø³ØªØ®Ø¯Ù… print() Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
"""
            try:
                python_response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "developer", "content": "You are a Python data analyst with a DataFrame named df."},
                        {"role": "user", "content": analysis_prompt}
                    ]
                )
                python_code = python_response.choices[0].message.content.strip()
            except Exception as e:
                return jsonify({"error": f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"}), 500

            print("GPT generated code:\n", python_code)
            err, output = exec_python_code(python_code, df)
            if err:
                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({
                    "role": "assistant",
                    "content": "Ù‡Ø°Ø§ ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ„ÙƒÙ† Ø­Ø¯Ø« Ø®Ø·Ø£:\n" + python_code
                })
                session['conversation_history'] = conversation_history
                return jsonify({"error": err, "analysis_code": python_code}), 500
            else:
                chart_data = None
                try:
                    chart_data = json.loads(output)
                except json.JSONDecodeError:
                    chart_data = None

                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({
                    "role": "assistant",
                    "content": "ÙƒÙˆØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n" + python_code + "\n\nØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:\n" + output
                })
                session['conversation_history'] = conversation_history
                # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                user = SessionLocal().query(User).filter(User.username == username).first()
                conv_id = None
                if user:
                    conv_id = save_conversation(user.id, question, output, classification='db_analysis')
                    conversation_history.append({"role": "assistant", "content": answer})
                    session['conversation_history'] = conversation_history
                   

                return jsonify({
                    "analysis_code": python_code,
                    "analysis_output": output,
                    "chart_data": chart_data,
                    "summary": generate_summary(output,question),
                    "classification": "db_analysis",
                    'conversation_id': conv_id
                })

        
                # =============== DB_ACTION (INSERT/UPDATE/DELETE/PLSQL) ===============
                
        elif classification == 'db_action':
            # 1) Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù† ChatGPT
            action_sql = natural_language_to_dml_action(question)
            if not action_sql:
                return jsonify({"error": "ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ SQL Ø§Ù„ØªØ¹Ø¯ÙŠÙ„."}), 500

            try:
                # 2) ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø­Ø±ÙˆÙ ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©:
                cleaned_sql = action_sql.strip()

                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ØµÙˆØ± ÙÙŠ ```sql ...``` Ù„Ùˆ ÙˆØ¬Ø¯
                if "```sql" in cleaned_sql:
                    cleaned_sql = cleaned_sql.split("```sql")[1].split("```")[0].strip()
                elif "```" in cleaned_sql:
                    cleaned_sql = cleaned_sql.split("```")[1].strip()

                cleaned_sql = cleaned_sql.rstrip(';')
                cleaned_sql = ' '.join(cleaned_sql.split())  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©

                print(f"User asked for DB action:\n{cleaned_sql}\n")

                # 3) Ù†ØªØ­Ù‚Ù‚ Ù‡Ù„ Ù‡Ùˆ PL/SQL blockØŸ Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ BEGIN Ø£Ùˆ DECLARE ÙÙŠ Ø¨Ø¯Ø§ÙŠØªÙ‡
                import re
                is_plsql = False
                # Ù…Ø«Ù„Ø§Ù‹ Ù„Ùˆ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙŠØ¨Ø¯Ø£ Ø¨Ù€ BEGIN Ø£Ùˆ DECLARE (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ø§Ù„Ø£Ø­Ø±Ù)
                # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‚Ø¯ ØªØ­ØªØ§Ø¬ ØªØºØ·ÙŠØ© Ø­Ø§Ù„Ø§Øª Ø£ÙƒØ«Ø± Ù…Ø«Ù„ "CREATE OR REPLACE PROCEDURE ..." Ø¥Ù„Ø®
                plsql_pattern = r"^\s*(BEGIN|DECLARE|CREATE\s+OR\s+REPLACE\s+PROCEDURE|CREATE\s+OR\s+REPLACE\s+FUNCTION)"
                if re.search(plsql_pattern, cleaned_sql, re.IGNORECASE):
                    is_plsql = True

                # 4) Ù„Ùˆ Ù„Ù… ÙŠÙƒÙ† PL/SQLØŒ Ù†Ø¬Ø±Ø¨ ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ù†ÙØµÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ Ù…Ù†Ù‚ÙˆØ·Ø©
                statements = []
                if not is_plsql:
                    # Ù†ÙØªØ±Ø¶ Ø£Ù†Ù‡ Ù‚Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯Ø© Ù…ÙØµÙˆÙ„Ø© Ø¨Ù€ ;
                    # split Ø¹Ù„Ù‰ ; Ø«Ù… ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„ÙØ±Ø§ØºØ§Øª
                    possible_stmts = cleaned_sql.split(';')
                    for stmt in possible_stmts:
                        stmt = stmt.strip()
                        if stmt:
                            statements.append(stmt)
                else:
                    # Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ø­Ø¯ (PL/SQL block)
                    statements = [cleaned_sql]

                # 5) Ù†Ù†ÙØ° ÙƒÙ„ Ø¬Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø­Ø¯Ø©
                total_rows_affected = 0
                success = True
                message = ""
                for stmt in statements:
                    print(f"Executing statement: {stmt}")
                    ok, msg, rows_aff = execute_sql_action(stmt)
                    if not ok:
                        # Ù„Ùˆ ÙØ´Ù„ Ø£Ø­Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
                        success = False
                        message = msg
                        logging.error(f"Ø®Ø·Ø£ ÙÙŠ Oracle Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø£Ù…Ø±: {stmt}\nØ±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£: {msg}")

                        # Ø·Ù„Ø¨ Ù…Ù† GPT Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
                        help_prompt = f"""
                        The following SQL/PLSQL statement caused an Oracle error:
                        {stmt}

                        Error message:
                        {message}

                        Please provide a corrected Oracle-compatible SQL statement or explanation.
                        """
                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {"role": "developer", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆØ±Ø§ÙƒÙ„."},
                                {"role": "user", "content": help_prompt}
                            ]
                        )
                        error_explanation = response.choices[0].message.content.strip()

                        return jsonify({
                            "error": error_explanation,
                            "action_sql": stmt
                        }), 500
                    else:
                        total_rows_affected += rows_aff

                # 6) Ø¥Ø°Ø§ Ù†Ø¬Ø­Øª ÙƒÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
                message = "The operation has been successfully completed."
                rows_affected = total_rows_affected

                # 7) ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù„Ø®Øµ
                action_data = {
                    "labels": ["Executed Statements", "Total Rows Affected", "Message"],
                    "values": [f"{len(statements)} statement(s)", rows_affected, message]
                }
                json_output = json.dumps(action_data)

                # 8) ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                final_text = generate_summary(json_output, question)

                summary_prompt = f"""
        Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø¹Ù† ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ:
        - Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
        - Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ù†ÙØ°Ø©: {len(statements)}
        - Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©: {rows_affected}
        - Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªÙ†ÙÙŠØ°: {message}

        Ø§Ù„Ù…Ù„Ø®Øµ ÙŠØ¬Ø¨ Ø£Ù†:
        1. ÙŠØ´Ø±Ø­ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù„ØºØ© Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ø¶Ø­Ø©
        2. ÙŠØ°ÙƒØ± Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©
        3. ÙŠÙˆØ¶Ø­ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        4. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù‡Ù…Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
        5. ÙŠØ³ØªØ¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ£Ø«ÙŠØ±Ù‡Ø§
        """
                try:
                    summary_response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "developer", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠÙˆÙ„Ø¯ ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¹Ù† Ø¹Ù…Ù„ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."},
                            {"role": "user", "content": summary_prompt}
                        ]
                    )
                    summary = summary_response.choices[0].message.content.strip()
                    from langdetect import detect
                    if detect(question) == 'ar':
                        summary = f"{summary}"
                except Exception as e:
                    summary = f"Ù…Ù„Ø§Ø­Ø¸Ø©: ØªØ¹Ø°Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ. {str(e)}"

                # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø£Ø³Ø·Ø± ÙÙŠ Ø§Ù„Ù…Ù„Ø®Øµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "SQL Command Executed:" Ø£Ùˆ Ù…Ø§ Ø´Ø§Ø¨Ù‡Ù‡
                import re
                summary = re.sub(
                    r"(?i)^\s*SQL Command Executed:.*$",
                    "",
                    summary,
                    flags=re.MULTILINE
                )
                summary = re.sub(
                    r"(?i)^\s*(SELECT|UPDATE|INSERT|DELETE)[^\n]*",
                    "",
                    summary,
                    flags=re.MULTILINE
                )

                # 9) Ø¥Ø¶Ø§ÙØ© ÙƒØªÙ„Ø© Ø§Ù„ÙƒÙˆØ¯ Ù„ÙƒÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù†ÙØ°
                # Ø¥Ù† Ø£Ø±Ø¯Øª Ø¬Ù…Ø¹Ù‡Ø§ ÙƒÙ„Ù‡Ø§ ÙÙŠ Ù…ÙƒØ§Ù† ÙˆØ§Ø­Ø¯:
                executed_block = "\n".join([f"```sql\n{stmt}\n```" for stmt in statements])
                final_text = summary + f"\n\n**Executed SQL Statement(s)**:\n{executed_block}"

                # 10) Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": final_text})
                session['conversation_history'] = conversation_history

                # 11) Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                user = SessionLocal().query(User).filter(User.username == username).first()
                if user:
                    conv_id = save_conversation(user.id, question, final_text, classification='db_action')
                    response_data = {
                        "action_sql": cleaned_sql,
                        "rows_affected": rows_affected,
                        "message": message,
                        "final_text": final_text,
                        "classification": "db_action",
                        "conversation_id": conv_id
                    }
                    return jsonify(response_data), 200, {'Content-Type': 'application/json; charset=utf-8'}

            except Exception as e:
                logging.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
                return jsonify({"error": f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}"}), 500





        # =============== DB_SQL (SELECT) ===============

        elif classification == 'db_sql':
            translated_question = translate_ar_to_en(question).lower()
            is_chart = any(word in translated_question for word in ["statistics", "chart", "graph", "plot"])

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù†
            sql_query = natural_language_to_sql(question=improved_question, is_chart=is_chart)
            if not sql_query:
                return jsonify({'error': 'Failed to generate SQL query'}), 500

            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                df = execute_sql_with_iterative_refinement(sql_query, max_retries=5)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ DataFrame
                if df is None or df.empty:
                    empty_answer = generate_empty_result_response(question)
                    # ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:
                    conv_id = save_conversation(user.id, question, empty_answer, classification='empty')
                    return jsonify({
                        'assistant_answer': empty_answer,
                        'classification': 'empty',
                        'conversation_id': conv_id
                    })

                # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ DataFrame
                df = df.fillna(0)
                df_records = df.to_dict(orient='records')

                if is_chart:
                    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                    df = df.rename(columns={
                        'JOB_TITLE': 'label',
                        'NUM_EMPLOYEES': 'value'
                    })

                    if 'label' in df.columns and 'value' in df.columns:
                        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                        df_subset = df.head(5).to_dict(orient='records')
                        chart_path = generate_chart(df, "label", "value")

                        analysis_prompt = f"""
        Ø§Ù„Ø³Ø¤Ø§Ù„: "{question}"
        Ù„Ù‚Ø¯ Ø§Ø³ØªØ®Ø±Ø¬Ù†Ø§ {len(df)} Ø³Ø¬Ù„Ø§Ù‹.
        Ù‡Ø°Ù‡ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø£ÙˆÙ„ {len(df_subset)} Ø³Ø¬Ù„:
        {df_subset}

        Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (Ù„Ù„Ø±Ø³Ù…):
        {df_records}

        "Your task is to analyze the provided database results and provide comprehensive, clear, and accurate responses. If the user's question is in Arabic, respond in Arabic. If the question is in English, respond in English. Always aim to provide in-depth insights, explain your reasoning, and suggest actionable recommendations when applicable. Ensure your responses are context-aware and cater to both technical and non-technical audiences."
                        """
                        try:
                            analysis_response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[
                                    {
                                        "role": "developer",
                                        "content": (
                                            "You are a highly intelligent and detail-oriented data analyst. "
                                            "Your task is to analyze the provided database results and provide comprehensive, "
                                            "clear, and accurate responses. If the user's question is in Arabic, respond in "
                                            "Arabic. If the question is in English, respond in English. Always aim to provide "
                                            "in-depth insights, explain your reasoning, and suggest actionable recommendations "
                                            "when applicable. Ensure your responses are context-aware and cater to both technical "
                                            "and non-technical audiences."
                                        ),
                                    },
                                    {
                                        "role": "user",
                                        "content": analysis_prompt,
                                    },
                                ]
                            )

                            assistant_answer = analysis_response.choices[0].message.content.strip()
                        except Exception as e:
                            assistant_answer = f"Error occurred while generating insights: {str(e)}"

                        conversation_history = session.get('conversation_history', [])
                        conversation_history.append({"role": "user", "content": question})
                        conversation_history.append({
                            "role": "assistant",
                            "content": assistant_answer
                        })
                        session['conversation_history'] = conversation_history

                        # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                        user = SessionLocal().query(User).filter(User.username == username).first()
                        if user:
                            save_conversation(user.id, question, assistant_answer, classification='db_sql')

                        return jsonify({
                            'results': df_records,
                            'chart_path': chart_path,
                            'assistant_answer': assistant_answer,
                            'classification': 'db_sql'
                        })
                    else:
                        return jsonify({'error': 'Invalid data for chart'}), 500
                else:
                    analysis_prompt = f"""
        Ø§Ù„Ø³Ø¤Ø§Ù„: "{question}"
        Ù‡Ø°Ù‡ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…:
        {df_records}

        "Your task is to analyze the provided database results and provide comprehensive, clear, and accurate responses. If the user's question is in Arabic, respond in Arabic. If the question is in English, respond in English. Always aim to provide in-depth insights, explain your reasoning, and suggest actionable recommendations when applicable. Ensure your responses are context-aware and cater to both technical and non-technical audiences."
                    """
                    try:
                        analysis_response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[
                                {"role": "developer", "content": "You are a helpful data analyst that uses the provided database result."},
                                {"role": "user", "content": analysis_prompt}
                            ]
                        )
                        assistant_answer = analysis_response.choices[0].message.content.strip()
                    except Exception as e:
                        assistant_answer = f"Error occurred while generating insights: {str(e)}"

                    conversation_history = session.get('conversation_history', [])
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({
                        "role": "assistant",
                        "content": assistant_answer
                    })
                    session['conversation_history'] = conversation_history

                    # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    user = SessionLocal().query(User).filter(User.username == username).first()
                    if user:
                        conv_id = save_conversation(user.id, question, assistant_answer, classification='db_sql')
                        conversation_history.append({"role": "user", "content": question})
                        conversation_history.append({"role": "assistant", "content": assistant_answer})
                        session['conversation_history'] = conversation_history

                    return jsonify({
                        'results': df_records,
                        'assistant_answer': assistant_answer,
                        'classification': 'db_sql',
                        'conversation_id': conv_id
                    })
            except Exception as e:
                return jsonify({'error': f'Error while processing SQL query: {str(e)}'}), 500


              # ===== Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø³Ø¦Ù„Ø© DDL =====
        if "ddl" in question_lower or "generate the ddl" in question_lower:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„
            table_match = re.search(r"from\s+(\w+)", question_lower, re.IGNORECASE)
            if table_match:
                table_name = table_match.group(1)
                ddl_code = get_ddl_for_table(table_name)
                if ddl_code:
                    answer = ddl_code  # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯ Ù…Ø¨Ø§Ø´Ø±Ø©Ù‹ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ
                else:
                    answer = "âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ DDL."
            else:
                answer = "â— ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ù…Ø«Ø§Ù„: generate the ddl from employees)."    

            # Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            user = SessionLocal().query(User).filter(User.username == username).first()
            if user:
                conv_id = save_conversation(user.id, question, answer, classification='db_sql')
                conversation_history = session.get('conversation_history', [])
                conversation_history.append({"role": "user", "content": question})
                conversation_history.append({"role": "assistant", "content": answer})
                session['conversation_history'] = conversation_history

            return jsonify({
                'results': [{'answer': answer}],
                'classification': 'db_sql',
                'conversation_id': conv_id
            })
        
        # =============== DEFAULT ===============
        else:
            # Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…
            conversation_history = session.get('conversation_history', [])
            if re.match(r"Ø§Ù†Øª\s+Ø§Ø³Ù…Ùƒ\s+(.+)", question, re.IGNORECASE):
                match = re.match(r"Ø§Ù†Øª\s+Ø§Ø³Ù…Ùƒ\s+(.+)", question, re.IGNORECASE)
                if match:
                    assistant_name = match.group(1).strip()
                    session['memory']['assistant_name'] = assistant_name
                    conversation_history.append({"role": "user", "content": question})
                    conversation_history.append({"role": "assistant", "content": f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù…ÙŠ Ø¥Ù„Ù‰ {assistant_name}."})
                    session['conversation_history'] = conversation_history
                    return jsonify({
                        'results': [{'answer': f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ø³Ù…ÙŠ Ø¥Ù„Ù‰ {assistant_name}."}],
                        'classification': 'general'
                    })

            system_content = "You are a helpful assistant."
            if 'assistant_name' in session.get('memory', {}):
                assistant_name = session['memory']['assistant_name']
                system_content = f"You are {assistant_name}, a helpful assistant."

            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "developer", "content": system_content},
                        *conversation_history,
                        {"role": "user", "content": question}
                    ]
                )
                answer = response.choices[0].message.content.strip()
            except:
                answer = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† ChatGPT."

            conversation_history.append({"role": "user", "content": question})
            conversation_history.append({"role": "assistant", "content": answer})
            session['conversation_history'] = conversation_history

            return jsonify({
                            'results': [{'answer': answer}],
                            'assistant_answer': answer,  # <-- Ø£Ø¶Ù Ù‡Ø°Ø§
                            'classification': 'general',
                            'conversation_id': conv_id
                        })

    except Exception as e:
        print(f"Error in /chat endpoint: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/feedback', methods=['POST'])
def collect_feedback():
    try:
        data = request.get_json()
        username = data.get('username')
        conversation_id = data.get('conversation_id')
        rating_type = data.get('rating_type')
        comments = data.get('comments')

        if not username or not conversation_id or ((rating_type is None or rating_type == "") and not comments):

            return jsonify({"error": "ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…."}), 400

        db = SessionLocal()
        user = db.query(User).filter(User.username == username).first()
        if not user:
            return jsonify({"error": "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."}), 404

        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙ†ØªÙ…ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        conversation = db.query(Conversation).filter(
            Conversation.conversation_id == conversation_id,
            Conversation.user_id == user.id
        ).first()

        if not conversation:
            return jsonify({"error": "Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ Ù„Ø§ ØªÙ†ØªÙ…ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."}), 404

        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        new_feedback = Feedback(
            conversation_id=conversation_id,
            rating_type=rating_type,
            comments=comments
        )
        db.add(new_feedback)
        db.commit()
        db.refresh(new_feedback)
        db.close()

        return jsonify({"message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø¨Ù†Ø¬Ø§Ø­."}), 201

    except Exception as e:
        print(f"Error in /feedback endpoint: {e}")
        return jsonify({"error": str(e)}), 500


# ====================================================================
#             ETL ÙˆØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª
# ====================================================================

def etl_process():
    session_db = SessionLocal()
    metadata.reflect(bind=engine)
    all_data = []

    for table in metadata.sorted_tables:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
        data = session_db.query(table).all()
        transformed_data = [dict(row) for row in data]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙØªØ§Ø­ _sa_instance_state
        for record in transformed_data:
            record.pop('_sa_instance_state', None)

        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ Ø§Ø³Ù…Ù‡
        all_data.append({
            "table_name": table.name,
            "columns": [column.name for column in table.columns],
            "sample_data": transformed_data[:5]  # Ø£Ø®Ø° Ø£ÙˆÙ„ 5 ØµÙÙˆÙ ÙÙ‚Ø· ÙƒØ¹ÙŠÙ†Ø©
        })

    session_db.close()
    train_llm(all_data)

def train_llm(data):
    for table_data in data:
        table_name = table_data["table_name"]
        columns = table_data["columns"]
        sample_data = table_data["sample_data"]

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        prompt = f"""
You are a database assistant. Here is a table schema and sample data for training:

Table Name: {table_name}
Columns: {', '.join(columns)}
Sample Data:
{sample_data}

Use this data to understand the structure of the table and answer user queries related to this table effectively.
        """

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "developer", "content": "You are a knowledgeable assistant trained on the database schema."},
                    {"role": "user", "content": prompt}
                ]
            )
            print(f"Training completed for table: {table_name}")
        except OpenAI.OpenAIError as e:
            print(f"Error training model for table {table_name}: {e}")

schedule.every().day.at("00:00").do(etl_process)

def run_schedule():
    while True:
        schedule.run_pending()
        time.sleep(60)



def update_fine_tune():
    # ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±ÙŠØ¨Øª prepare_finetune.py Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    logger.info("Running update_fine_tune...")
    python_executable = sys.executable
    subprocess.run([python_executable, "prepare_finetune.py"])

scheduler = BackgroundScheduler()
scheduler.add_job(update_fine_tune, 'cron', hour=0, minute=0)  # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ù‡
scheduler.add_job(send_weekly_report_with_chart, 'cron', hour=6, minute=0)
try:
    scheduler.start()
except Exception as e:
    print(f"Error starting scheduler: {e}")

if __name__ == '__main__':
    schedule_thread = threading.Thread(target=run_schedule)
    schedule_thread.daemon = True
    schedule_thread.start()
    app.run(debug=False, host='0.0.0.0', port=5002)